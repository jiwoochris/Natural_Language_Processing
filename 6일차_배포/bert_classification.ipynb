{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"bert_classification.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"ZhNm9JaF1uct"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["!pip install transformers"],"metadata":{"id":"bVmB8Ln41zLT"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#construct dataset  \n","dataset구성\n","spam dataset을 하나씩 반환하며  \n","BertTokenzier를 통해 tokenziation후 input_ids, token_type_ids, attention mask를 tensor로 바꿔서 return  \n","또한 label이 spam일때는 1 ham일때는 0을 함께 return  "],"metadata":{"id":"68VPO5kS10dl"}},{"cell_type":"code","source":[""],"metadata":{"id":"-NI5SX_Z2Hfj"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##Model\n","BertModel을 이용해서 구현  \n","BertModel의 cls token에 대한 output인 pooler_output에 linear를 통해 2차원 벡터로 변환  \n","BertModel: https://huggingface.co/docs/transformers/model_doc/bert#transformers.BertModel"],"metadata":{"id":"a_1-izAu2H6G"}},{"cell_type":"code","source":[""],"metadata":{"id":"St-O1cxh2ibK"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##train\n","cross entropy loss와 Adam을 통해 train"],"metadata":{"id":"bQN7lqE22eMu"}},{"cell_type":"code","source":[""],"metadata":{"id":"GZm0ceuw2iE9"},"execution_count":null,"outputs":[]}]}